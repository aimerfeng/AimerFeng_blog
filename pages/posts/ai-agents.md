---
title: AI Agent å¼€å‘å…¥é—¨ - æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªæ™ºèƒ½ä»£ç†
date: 2024-12-17
description: ä»é›¶å¼€å§‹å­¦ä¹  AI Agent å¼€å‘ï¼Œä½¿ç”¨ Python å’Œ LangChain æ„å»ºèƒ½å¤Ÿè‡ªä¸»å®Œæˆä»»åŠ¡çš„æ™ºèƒ½ä»£ç†
tags: [ai, llm, python]
---

# AI Agent å¼€å‘å…¥é—¨

AI Agentï¼ˆæ™ºèƒ½ä»£ç†ï¼‰æ˜¯èƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒã€åšå‡ºå†³ç­–å¹¶é‡‡å–è¡ŒåŠ¨çš„ AI ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„èŠå¤©æœºå™¨äººä¸åŒï¼ŒAgent å¯ä»¥ä½¿ç”¨å·¥å…·ã€è®¿é—®å¤–éƒ¨æ•°æ®ï¼Œå¹¶è‡ªä¸»å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

## ä»€ä¹ˆæ˜¯ AI Agentï¼Ÿ

AI Agent çš„æ ¸å¿ƒç‰¹å¾ï¼š

- ğŸ§  **è‡ªä¸»å†³ç­–** - æ ¹æ®ç›®æ ‡è‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œä»»åŠ¡
- ğŸ”§ **å·¥å…·ä½¿ç”¨** - èƒ½å¤Ÿè°ƒç”¨ APIã€æœç´¢ç½‘ç»œã€æ‰§è¡Œä»£ç 
- ğŸ’¾ **è®°å¿†èƒ½åŠ›** - ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†
- ğŸ”„ **è¿­ä»£æ”¹è¿›** - æ ¹æ®åé¦ˆè°ƒæ•´ç­–ç•¥

### Agent æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI Agent                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   LLM   â”‚  â”‚ Memory  â”‚  â”‚ Planner â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚            â”‚            â”‚       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                    â”‚                    â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚            â”‚   Executor    â”‚            â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tool 1  â”‚ Tool 2â”‚ Tool 3â”‚ Tool N  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç¯å¢ƒå‡†å¤‡

é¦–å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–ï¼š

```bash
pip install langchain langchain-openai python-dotenv
```

é…ç½®ç¯å¢ƒå˜é‡ï¼š

```python
# .env
OPENAI_API_KEY=sk-your-api-key
```

## åŸºç¡€ Agent å®ç°

### 1. ç®€å•çš„ ReAct Agent

ReActï¼ˆReasoning + Actingï¼‰æ˜¯æœ€å¸¸ç”¨çš„ Agent æ¨¡å¼ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain import hub

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)

# å®šä¹‰å·¥å…·
def search_web(query: str) -> str:
    """æ¨¡æ‹Ÿç½‘ç»œæœç´¢"""
    return f"æœç´¢ç»“æœ: å…³äº '{query}' çš„æœ€æ–°ä¿¡æ¯..."

def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

tools = [
    Tool(
        name="Search",
        func=search_web,
        description="ç”¨äºæœç´¢ç½‘ç»œè·å–æœ€æ–°ä¿¡æ¯"
    ),
    Tool(
        name="Calculator",
        func=calculate,
        description="ç”¨äºè®¡ç®—æ•°å­¦è¡¨è¾¾å¼"
    )
]

# è·å– ReAct prompt æ¨¡æ¿
prompt = hub.pull("hwchase17/react")

# åˆ›å»º Agent
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# è¿è¡Œ Agent
result = agent_executor.invoke({
    "input": "æ¯”ç‰¹å¸ç°åœ¨çš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿå¦‚æœæˆ‘æœ‰ 0.5 ä¸ªæ¯”ç‰¹å¸ï¼Œä»·å€¼å¤šå°‘ç¾å…ƒï¼Ÿ"
})
print(result["output"])
```

### 2. å¸¦è®°å¿†çš„ Agent

```python
from langchain.memory import ConversationBufferMemory
from langchain.agents import AgentExecutor, create_react_agent

# åˆ›å»ºè®°å¿†ç»„ä»¶
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# åˆ›å»ºå¸¦è®°å¿†çš„ Agent
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True
)

# å¤šè½®å¯¹è¯
agent_executor.invoke({"input": "æˆ‘å«ç„¶ç„¶ï¼Œè¯·è®°ä½æˆ‘çš„åå­—"})
agent_executor.invoke({"input": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"})  # Agent ä¼šè®°ä½
```

## è‡ªå®šä¹‰å·¥å…·å¼€å‘

### ä½¿ç”¨è£…é¥°å™¨å®šä¹‰å·¥å…·

```python
from langchain.tools import tool
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    query: str = Field(description="æœç´¢å…³é”®è¯")
    max_results: int = Field(default=5, description="æœ€å¤§ç»“æœæ•°")

@tool("advanced_search", args_schema=SearchInput)
def advanced_search(query: str, max_results: int = 5) -> str:
    """
    é«˜çº§æœç´¢å·¥å…·ï¼Œæ”¯æŒé™åˆ¶ç»“æœæ•°é‡ã€‚
    ç”¨äºæœç´¢ç½‘ç»œè·å–ä¿¡æ¯ã€‚
    """
    # å®é™…å®ç°ä¸­å¯ä»¥è°ƒç”¨æœç´¢ API
    results = [f"ç»“æœ {i+1}: å…³äº {query} çš„ä¿¡æ¯" for i in range(max_results)]
    return "\n".join(results)
```

### API è°ƒç”¨å·¥å…·

```python
import requests
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    # ç¤ºä¾‹ API è°ƒç”¨
    api_key = "your-api-key"
    url = f"https://api.weatherapi.com/v1/current.json?key={api_key}&q={city}"
    
    try:
        response = requests.get(url)
        data = response.json()
        return f"{city} å½“å‰æ¸©åº¦: {data['current']['temp_c']}Â°C"
    except Exception as e:
        return f"è·å–å¤©æ°”å¤±è´¥: {str(e)}"

@tool
def execute_code(code: str) -> str:
    """æ‰§è¡Œ Python ä»£ç å¹¶è¿”å›ç»“æœ"""
    try:
        # æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒéœ€è¦æ²™ç®±éš”ç¦»
        exec_globals = {}
        exec(code, exec_globals)
        return str(exec_globals.get('result', 'ä»£ç æ‰§è¡ŒæˆåŠŸ'))
    except Exception as e:
        return f"æ‰§è¡Œé”™è¯¯: {str(e)}"
```

## é«˜çº§ Agent æ¨¡å¼

### 1. å¤š Agent åä½œ

```python
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

class ResearchAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
    
    def research(self, topic: str) -> str:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶å‘˜ï¼Œæ“…é•¿æ”¶é›†å’Œæ•´ç†ä¿¡æ¯ã€‚"),
            HumanMessage(content=f"è¯·ç ”ç©¶ä»¥ä¸‹ä¸»é¢˜å¹¶æä¾›è¯¦ç»†æŠ¥å‘Š: {topic}")
        ]
        return self.llm.invoke(messages).content

class WriterAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.8)
    
    def write(self, research: str, style: str = "åšå®¢") -> str:
        messages = [
            SystemMessage(content=f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{style}ä½œè€…ã€‚"),
            HumanMessage(content=f"åŸºäºä»¥ä¸‹ç ”ç©¶å†…å®¹ï¼Œæ’°å†™ä¸€ç¯‡æ–‡ç« :\n\n{research}")
        ]
        return self.llm.invoke(messages).content

class EditorAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.3)
    
    def edit(self, content: str) -> str:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ç¼–è¾‘ï¼Œè´Ÿè´£æ ¡å¯¹å’Œæ”¹è¿›æ–‡ç« ã€‚"),
            HumanMessage(content=f"è¯·æ ¡å¯¹å¹¶æ”¹è¿›ä»¥ä¸‹æ–‡ç« :\n\n{content}")
        ]
        return self.llm.invoke(messages).content

# åä½œæµç¨‹
def create_article(topic: str) -> str:
    researcher = ResearchAgent()
    writer = WriterAgent()
    editor = EditorAgent()
    
    # 1. ç ”ç©¶
    research = researcher.research(topic)
    print("ğŸ“š ç ”ç©¶å®Œæˆ")
    
    # 2. å†™ä½œ
    draft = writer.write(research)
    print("âœï¸ åˆç¨¿å®Œæˆ")
    
    # 3. ç¼–è¾‘
    final = editor.edit(draft)
    print("âœ… ç¼–è¾‘å®Œæˆ")
    
    return final

# ä½¿ç”¨
article = create_article("Web3 ä¸ AI çš„èåˆè¶‹åŠ¿")
```

### 2. è‡ªæˆ‘åæ€ Agent

```python
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

class ReflectiveAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.max_iterations = 3
    
    def solve(self, problem: str) -> str:
        solution = self._initial_solution(problem)
        
        for i in range(self.max_iterations):
            critique = self._critique(problem, solution)
            
            if "æ»¡æ„" in critique or "æ­£ç¡®" in critique:
                break
            
            solution = self._improve(problem, solution, critique)
            print(f"ğŸ”„ è¿­ä»£ {i+1} å®Œæˆ")
        
        return solution
    
    def _initial_solution(self, problem: str) -> str:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªé—®é¢˜è§£å†³ä¸“å®¶ã€‚"),
            HumanMessage(content=f"è¯·è§£å†³ä»¥ä¸‹é—®é¢˜:\n{problem}")
        ]
        return self.llm.invoke(messages).content
    
    def _critique(self, problem: str, solution: str) -> str:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è¯„å®¡å‘˜ã€‚"),
            HumanMessage(content=f"""
é—®é¢˜: {problem}

è§£å†³æ–¹æ¡ˆ: {solution}

è¯·è¯„ä¼°è¿™ä¸ªè§£å†³æ–¹æ¡ˆçš„è´¨é‡ï¼ŒæŒ‡å‡ºä»»ä½•é—®é¢˜æˆ–æ”¹è¿›ç©ºé—´ã€‚
å¦‚æœè§£å†³æ–¹æ¡ˆå·²ç»å¾ˆå¥½ï¼Œè¯·è¯´"æ»¡æ„"ã€‚
""")
        ]
        return self.llm.invoke(messages).content
    
    def _improve(self, problem: str, solution: str, critique: str) -> str:
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªé—®é¢˜è§£å†³ä¸“å®¶ã€‚"),
            HumanMessage(content=f"""
é—®é¢˜: {problem}

å½“å‰è§£å†³æ–¹æ¡ˆ: {solution}

è¯„å®¡æ„è§: {critique}

è¯·æ ¹æ®è¯„å®¡æ„è§æ”¹è¿›è§£å†³æ–¹æ¡ˆã€‚
""")
        ]
        return self.llm.invoke(messages).content
```

## å®æˆ˜ï¼šæ„å»ºä»£ç åŠ©æ‰‹ Agent

```python
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import tool
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
import subprocess

@tool
def read_file(filepath: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"è¯»å–å¤±è´¥: {str(e)}"

@tool
def write_file(filepath: str, content: str) -> str:
    """å†™å…¥æ–‡ä»¶å†…å®¹"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"æˆåŠŸå†™å…¥ {filepath}"
    except Exception as e:
        return f"å†™å…¥å¤±è´¥: {str(e)}"

@tool
def run_python(code: str) -> str:
    """æ‰§è¡Œ Python ä»£ç """
    try:
        result = subprocess.run(
            ['python', '-c', code],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            return result.stdout or "æ‰§è¡ŒæˆåŠŸï¼Œæ— è¾“å‡º"
        return f"é”™è¯¯: {result.stderr}"
    except Exception as e:
        return f"æ‰§è¡Œå¤±è´¥: {str(e)}"

# åˆ›å»ºä»£ç åŠ©æ‰‹
tools = [read_file, write_file, run_python]

prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·ï¼š
1. é˜…è¯»å’Œåˆ†æä»£ç 
2. ç¼–å†™å’Œä¿®æ”¹ä»£ç 
3. è¿è¡Œå’Œæµ‹è¯•ä»£ç 

è¯·ä¸€æ­¥æ­¥æ€è€ƒï¼Œç¡®ä¿ä»£ç æ­£ç¡®åå†æ‰§è¡Œã€‚"""),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

llm = ChatOpenAI(model="gpt-4", temperature=0)
agent = create_openai_functions_agent(llm, tools, prompt)
code_assistant = AgentExecutor(agent=agent, tools=tools, verbose=True)

# ä½¿ç”¨ç¤ºä¾‹
result = code_assistant.invoke({
    "input": "åˆ›å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œå®ç°æ–æ³¢é‚£å¥‘æ•°åˆ—å‡½æ•°ï¼Œç„¶åæµ‹è¯•å®ƒ"
})
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
from langchain.callbacks import get_openai_callback

def safe_agent_run(agent_executor, input_text: str):
    try:
        with get_openai_callback() as cb:
            result = agent_executor.invoke({"input": input_text})
            print(f"Token ä½¿ç”¨: {cb.total_tokens}")
            return result
    except Exception as e:
        return {"output": f"Agent æ‰§è¡Œå¤±è´¥: {str(e)}"}
```

### 2. é™åˆ¶è¿­ä»£æ¬¡æ•°

```python
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    max_iterations=10,  # é˜²æ­¢æ— é™å¾ªç¯
    max_execution_time=60,  # è¶…æ—¶é™åˆ¶ï¼ˆç§’ï¼‰
    early_stopping_method="generate"
)
```

### 3. æ—¥å¿—å’Œç›‘æ§

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LoggingCallback:
    def on_tool_start(self, tool_name: str, input_str: str):
        logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
        logger.info(f"   è¾“å…¥: {input_str[:100]}...")
    
    def on_tool_end(self, output: str):
        logger.info(f"   è¾“å‡º: {output[:100]}...")
```

## æ€»ç»“

AI Agent å¼€å‘æ˜¯ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸï¼Œæ ¸å¿ƒè¦ç‚¹ï¼š

- ğŸ¯ æ˜ç¡® Agent çš„ç›®æ ‡å’Œè¾¹ç•Œ
- ğŸ”§ è®¾è®¡å¥½ç”¨çš„å·¥å…·é›†
- ğŸ’¾ åˆç†ç®¡ç†è®°å¿†å’Œä¸Šä¸‹æ–‡
- ğŸ›¡ï¸ åšå¥½é”™è¯¯å¤„ç†å’Œå®‰å…¨é˜²æŠ¤

ä¸‹ä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ LLM åº”ç”¨å¼€å‘çš„æ›´å¤šæŠ€å·§ï¼

---

<div class="mt-8 p-4 glass-card">
  <p class="text-sm op-75">
    ğŸ¤– æœ¬æ–‡ä»£ç å·²åœ¨ GitHub å¼€æºï¼Œæ¬¢è¿äº¤æµè®¨è®ºï¼
  </p>
</div>
